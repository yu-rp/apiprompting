{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Using API on MM-Vet and LLaVA-Wild"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation: Dataset\n",
    "We will use two datasets: MM-Vet and LLaVA-Wild. \n",
    "- You can download MM-Vet [here](https://github.com/yuweihao/MM-Vet/releases/download/v1/mm-vet.zip).\n",
    "- You can ownload LLaVA-Wild following the instruction [here](https://github.com/haotian-liu/LLaVA/blob/main/docs/LLaVA_Bench.md). \n",
    "\n",
    "We store the downloaded and unzipped datasets in the `dataset/mm-vet` folder and the `dataset/LLaVA_Wild` folder, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation: API\n",
    "You can create the enviroment for API following the instruction in `ReadMe.md`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation: Inference Package\n",
    "The inference LVLM is LLaVA1.5. \n",
    "We use [sglang](https://github.com/sgl-project/sglang?tab=readme-ov-file#frontend-structured-generation-language-sglang) package to accelerate inference.\n",
    "You can run the following commands in your command shell to create an environment for Sglang and install the necessary dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Create a conda environment\n",
    "conda create --name sglang python=3.11 -y\n",
    "# 2. Activate the environment\n",
    "conda activate sglang\n",
    "# 3. Clone the repo\n",
    "git clone https://github.com/sgl-project/sglang.git\n",
    "cd sglang\n",
    "# 4. (Pptional) The commit id of the Sglang repo we used is \"83d2b30d759ec2e7e781d4da7d4c98c0b778b941\". You can checkout to this commit id by running the following command.\n",
    "git checkout 83d2b30d759ec2e7e781d4da7d4c98c0b778b941\n",
    "# 5. Install Sglang\n",
    "pip install --upgrade pip\n",
    "pip install -e \"python[all]\"\n",
    "# 6. (Optional) Install the dataset manager package. You may use you own code to import the dataset.\n",
    "cd ../API/DatasetManager\n",
    "pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Troubleshooting**\n",
    "\n",
    "- **ModuleNotFoundError**: No module named 'vllm.transformers_utils.configs.qwen'\n",
    "\n",
    "    vLLM removed qwen in v0.3.3. Downgrading vllm package to 0.3.2 should solve this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install vllm==0.3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation: Inference Script\n",
    "We use `sglang_inference.py` to conduct inference, which can be run as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "cd .\n",
    "\n",
    "python sglang_inference.py \\\n",
    "    --dataset mmvet \\\n",
    "    --batch_size 8 \\\n",
    "    --prompt_name masked \\\n",
    "    --image_folder /path/to/image_folder \\\n",
    "    --output_folder /path/to/output_folder \\\n",
    "    --exp_name mmvet_infrence \\\n",
    "    --port_value 30000 \n",
    "\n",
    "# --dataset: Dataset, e.g., mmvet, LLaVA_Wild.\n",
    "# --batch_size: Batch size used in Sglang. Increasing batch_size to speed up.\n",
    "# --prompt_name: Prompt name, such as, masked, empty, sbs.\n",
    "# --image_folder: Folder containing the masked image, only used when prompt_name is masked.\n",
    "# --output_folder: Output Folder.\n",
    "# --exp_name: Experiment name, used as the file name of the output.\n",
    "# --port_value: Port of Sglang server. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API for MM-Vet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following command in the command shell to generate the masked images using API. The masked images will be stored in the folder `../results/APICLIP_mmvet_ViT-L-14-336_22/1_3_BICUBIC_0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "cd API/API_CLIP\n",
    "\n",
    "python main.py \\\n",
    "  --dataset mmvet \\  \n",
    "  --range 0 300 \\ \n",
    "  --model_name ViT-L-14-336 \\ \n",
    "  --layer_index 22 \\  \n",
    "  --batch_size 8 \\ \n",
    "  --output_folder \"../results\" \\\n",
    "  --interpolate_method_name BICUBIC \\ \n",
    "  --enhance_coe 1 \\\n",
    "  --kernel_size 3 \\\n",
    "  --grayscale 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start a Sglang server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "CUDA_VISIBLE_DEVICES=0 python3 -m sglang.launch_server \\ \n",
    "    --model-path liuhaotian/llava-v1.5-13b \\ \n",
    "    --tokenizer-path llava-hf/llava-1.5-13b-hf \\ \n",
    "    --port 30000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference by directly inputting the query and the orginal image into LLaVA1.5. The result will be store in `../results/llava15_mmvet_empty.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "cd .\n",
    "\n",
    "python sglang_inference.py \\\n",
    "    --dataset mmvet \\\n",
    "    --batch_size 8 \\\n",
    "    --prompt_name empty \\\n",
    "    --image_folder \"\" \\\n",
    "    --output_folder ../results \\\n",
    "    --exp_name llava15_mmvet_empty \\\n",
    "    --port_value 30000 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference by inputting the query and the API-masked image into LLaVA1.5. The result will be store in `../results/llava15_mmvet_api.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "cd .\n",
    "\n",
    "python sglang_inference.py \\\n",
    "    --dataset mmvet \\\n",
    "    --batch_size 8 \\\n",
    "    --prompt_name empty \\\n",
    "    --image_folder \"../results/APICLIP_mmvet_ViT-L-14-336_22/1_3_BICUBIC_0\" \\\n",
    "    --output_folder ../results \\\n",
    "    --exp_name llava15_mmvet_api \\\n",
    "    --port_value 30000 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the output file to meet the format requirements of the MM-Vet online evaluator. \n",
    "- `llava15_mmvet_empty.json` → `llava15_mmvet_empty_standard.json`\n",
    "- `llava15_mmvet_api.json` → `llava15_mmvet_api_standard.json`\n",
    "\n",
    "Submit the modified files to the [MM-Vet online evaluator](https://huggingface.co/spaces/whyu/MM-Vet_Evaluator) to obtain the final scores. For example, we got\n",
    "\n",
    "|        | Without API | With API |\n",
    "|:------:|:-----------:|:--------:|\n",
    "| MM-Vet |     31.2    |   33.9   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API for LLaVA-Wild"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following command in the command shell to generate the masked images using API. The masked images will be stored in the folder `../results/APICLIP_LLaVA_Wild_ViT-L-14-336_22/10_7_LANCZOS_200`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "cd API/API_CLIP\n",
    "\n",
    "python main.py \\\n",
    "  --dataset LLaVA_Wild \\  \n",
    "  --range 0 100 \\ \n",
    "  --model_name ViT-L-14-336 \\\n",
    "  --layer_index 22 \\  \n",
    "  --batch_size 8 \\ \n",
    "  --output_folder \"../results\" \\\n",
    "  --interpolate_method_name LANCZOS \\ \n",
    "  --enhance_coe 10 \\\n",
    "  --kernel_size 7 \\\n",
    "  --grayscale 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start a Sglang server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "CUDA_VISIBLE_DEVICES=0 python3 -m sglang.launch_server \\ \n",
    "    --model-path liuhaotian/llava-v1.5-13b \\ \n",
    "    --tokenizer-path llava-hf/llava-1.5-13b-hf \\ \n",
    "    --port 30000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference by directly inputting the query and the orginal image into LLaVA1.5. The result will be store in `../results/llava15_llava_wild_empty.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "cd .\n",
    "\n",
    "python sglang_inference.py \\\n",
    "    --dataset LLaVA_Wild \\\n",
    "    --batch_size 8 \\\n",
    "    --prompt_name empty \\\n",
    "    --image_folder \"\" \\\n",
    "    --output_folder ../results \\\n",
    "    --exp_name llava15_llava_wild_empty \\\n",
    "    --port_value 30000 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference by inputting the query and the API-masked image into LLaVA1.5. The result will be store in `../results/llava15_llava_wild_api.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "cd .\n",
    "\n",
    "python sglang_inference.py \\\n",
    "    --dataset LLaVA_Wild \\\n",
    "    --batch_size 8 \\\n",
    "    --prompt_name empty \\\n",
    "    --image_folder \"../results/APICLIP_LLaVA_Wild_ViT-L-14-336_22/10_7_LANCZOS_200\" \\\n",
    "    --output_folder ../results \\\n",
    "    --exp_name llava15_llava_wild_api \\\n",
    "    --port_value 30000 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the output file to meet the format requirements of the MM-Vet online evaluator. \n",
    "- `llava15_llava_wild_empty.json` → `llava15_llava_wild_empty_standard.jsonl`\n",
    "- `llava15_llava_wild_api.json` → `llava15_llava_wild_api_standard.jsonl`\n",
    "\n",
    "Follow the evaluation [pipeline](https://github.com/haotian-liu/LLaVA/blob/main/docs/Evaluation.md#llava-bench-in-the-wild) in LLaVA Repo to obtain the final score. For example, we got\n",
    "\n",
    "|           | Without API | With API |\n",
    "|:---------:|:-----------:|:--------:|\n",
    "|LLaVA-Wild |     67.6    |   71.5   |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
